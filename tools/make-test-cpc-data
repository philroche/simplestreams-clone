#!/usr/bin/python

import argparse
import copy
import errno
from Cheetah.Template import Template
import json
import os
import os.path
import subprocess
import sys
import yaml

import toolutil

CONTENT_EXT = ".yaml"

GET_QUERY = ("rsync -avz --delete --exclude \".bzr/*\" " +
             "cloud-images.ubuntu.com::uec-images/query/ ci-query")

# whitelist of releases
RELEASES = (
#    "hardy",
    "lucid",
    "oneiric",
    "precise",
    "quantal",
    "raring",
)

# whitelist of builds
BUILDS = ("server")

NUM_DAILIES = 4

REL2VER = {
    "hardy": {'version': "8.04", 'devname': "Hardy Heron"},
    "lucid": {'version': "10.04", 'devname': "Lucid Lynx"},
    "oneiric": {'version': "11.10", 'devname': "Oneiric Ocelot"},
    "precise": {'version': "12.04", 'devname': "Precise Pangolin"},
    "quantal": {'version': "12.10", 'devname': "Quantal Quetzal"},
    "raring": {'version': "13.04", 'devname': "Raring Ringtail"},
}

STREAM_TEMPLATE = """
description: Image ids for Ubuntu Cloud Ubuntu ${release.version} (${release.devname}) on ${cloud.name}/${region.name}
format: stream-1.0
item_groups:
#for $item_group in $item_groups:
 - serial: ${item_group.serial}
   label: ${item_group.label}
   items:
   #for $item in $item_group.items
    #if $item.vtype == "hvm"
    #set prefix="hvm/"
    #else if $item.root_store == "instance-store"
    #set prefix=""
    #else
    #set prefix=$item.root_store + "/"
    #end if
    #if $item_group.label == "daily":
    #set name="ubuntu-" + $release.name + "-daily-" + $arch.name + "-" + $build.name + "-" + $item_group.serial
    #else
    #set name="ubuntu-" + $release.name + "-" + $release.version + "-" + $arch.name + "-" + $build.name + "-" + $item_group.serial
    #end if
    - name: $name
      root_store: ${item.root_store}
      virt_type: ${item.vtype}
      image_id: ${item.id}
   #end for
#end for

tags:
  region: ${region.name}
  arch: ${arch.name}
  release: ${release.name}
  version: "${release.version}"
  stream: ${stream.name}
  cloud: ${cloud.name}
  region: ${region.name}
  build: ${build.name}
  endpoint: https://ec2.${region.name}.amazonaws.com
"""

COLLECTION_TEMPLATE = """
description: Ubuntu Certified Public Cloud image id streams
format: stream-collection:1.0
streams:
#for $stream in $streams:
 - url: $stream.url
 #for $tag in $stream.tags:
   $tag: $stream.tags[$tag]
 #end for
#end for

tags:
 #for tag in $tags:
 $tag: ${tags[tag]}
 #end for
"""

def load_query(path, cloud="aws", tree=None):
    streams = [f[0:-len(".latest.txt")]
               for f in os.listdir("ci-query")
                   if f.endswith("latest.txt")]
    if tree is None:
        tree = {}

    # $stream/$cloud/$region/$buildname/$release/$arch
    # $stream/aws/$region/${buildname}/${release['name']}/${arch}"]
    for stream in streams:
        if stream not in tree:
            tree[stream] = {cloud: {}}
        id_files = []

        latest_f = "%s/%s.latest.txt" % (path, stream)

        # get the builds and releases
        with open(latest_f) as fp:
            for line in fp.readlines():
                (rel, build, _stream, _serial) = line.split("\t")

                if ((len(BUILDS) and build not in BUILDS) or
                    (len(RELEASES) and rel not in RELEASES)):
                    continue

                id_files.append("%s/%s/%s/%s.txt" %
                    (path, rel, build, stream))

        cdata = tree[stream][cloud]
        for id_file in id_files:
            lines = reversed(open(id_file).readlines())
            for line in lines:
                line = line.rstrip("\n\r") + "\tBOGUS"
                (rel, build, label, serial, store, arch, region,
                 iid, _kern, _rmd, vtype, _bogus) = line.split("\t", 11)

                if region not in cdata:
                    cdata[region] = {}
                if build not in cdata[region]:
                    cdata[region][build] = {}
                if rel not in cdata[region][build]:
                    cdata[region][build][rel] = {}
                if arch not in cdata[region][build][rel]:
                    cdata[region][build][rel][arch] = []

                item_groups = cdata[region][build][rel][arch]

                item_group = None
                for ig in item_groups:
                    if ig['serial'] == serial:
                        item_group = ig

                if not item_group:
                    # check NUM_DAILIES
                    if (stream == "daily" and
                        len(item_groups) == NUM_DAILIES):
                        break
                    item_group = {'serial': serial, 'items': []}
                    item_groups.append(item_group)

                # item groups (same serial) all have the same label
                item_group['label'] = label
                cur_item = {'root_store': store,
                            'vtype': vtype, 'id': iid}
                item_group['items'].append(cur_item)

    return tree


def process(cur, data, level, layout, callback, passthrough):
    for item in cur:
        if isinstance(item, dict):
            data[layout[level]['name']] = item.copy()
        else:
            data[layout[level]['name']] = {'name': item}

        curdatum = data[layout[level]['name']]

        if callable(layout[level].get('populate', None)):
            layout[level]['populate'](curdatum)

        if (level + 1) == len(layout):
            path = '/'.join([data[n['name']]['name'] for n in layout])
            callback(cur[item], data, path, passthrough)
        else:
            process(cur[item], data, level + 1, layout, callback,
                    passthrough)


def name2ver(indict):
    indict.update(toolutil.REL2VER[indict['name']])


def writer(item, data, path, passthrough):
    params = data.copy()
    params['item_groups'] = item
    url = "%s.yaml" % path
    fname = "%s/%s" % (passthrough['output_d'], url)
    toolutil.mkdir_p(os.path.dirname(fname))
    open(fname, "w").write(toolutil.render_string(passthrough['template'], params))
    passthrough['streams'].append(url)
    sys.stderr.write(fname + "\n")


def main():
    parser = argparse.ArgumentParser(description="create example content tree")

    parser.add_argument("query_tree", metavar='query_tree',
                        help=('read in content from /query tree. Hint: ' +
                              GET_QUERY))

    parser.add_argument("out_d", metavar='out_d',
                        help=('create content under output_dir'))

    parser.add_argument('--sign', action='store_true', default=False,
                        help='sign all generated files')

    args = parser.parse_args()

    tree = load_query(args.query_tree, cloud="aws")

    layout = [
        {"name": "stream"},
        {"name": "cloud"},
        {"name": "region"},
        {"name": "build"},
        {"name": "release", "populate": name2ver},
        {"name": "arch"},
    ]

    passthrough = {'output_d': args.out_d,
        'template': STREAM_TEMPLATE.lstrip(),
        'streams': [],
        }
    process(tree, {}, 0, layout, writer, passthrough)

    tmpl = COLLECTION_TEMPLATE.lstrip()

    def collwriter(path, path_prefix, collection):
        coll_file = "%s%sstreams%s" % (path_prefix, path, CONTENT_EXT)
        with open(coll_file, "w") as cfp:
            cfp.write(toolutil.render_string(tmpl, collection))

    toolutil.process_collections(passthrough['streams'], args.out_d,
                                 collwriter)

    return

if __name__ == '__main__':
    sys.exit(main())

# vi: ts=4 expandtab
