#!/usr/bin/python

import argparse
import copy
import errno
from Cheetah.Template import Template
import json
import os
import os.path
import subprocess
import sys
import yaml

import toolutil

CONTENT_EXT = ".js"
SIGNED_CONTENT_EXT = ".sjs"

GET_QUERY = ("rsync -avz --delete --exclude \".bzr/*\" " +
             "cloud-images.ubuntu.com::uec-images/query/ ci-query")

# whitelist of releases
RELEASES = (
#    "hardy",
    "lucid",
    "oneiric",
    "precise",
    "quantal",
    "raring",
)

# whitelist of builds
BUILDS = ("server")

NUM_DAILIES = 4

REL2VER = {
    "hardy": {'version': "8.04", 'devname': "Hardy Heron"},
    "lucid": {'version': "10.04", 'devname': "Lucid Lynx"},
    "oneiric": {'version': "11.10", 'devname': "Oneiric Ocelot"},
    "precise": {'version': "12.04", 'devname': "Precise Pangolin"},
    "quantal": {'version': "12.10", 'devname': "Quantal Quetzal"},
    "raring": {'version': "13.04", 'devname': "Raring Ringtail"},
}

STREAM_TEMPLATE = """
description: Image ids for Ubuntu Cloud Ubuntu ${release.version} (${release.devname}) on ${cloud.name}/${region.name}
format: stream:1.0
iqn: $iqn

item_groups:
#for $item_group in $item_groups:
 - serial: ${item_group.serial}
   label: ${item_group.label}
   items:
   #for $item in $item_group.items
    #if $item.vtype == "hvm"
    #set prefix="hvm/"
    #else if $item.root_store == "instance-store"
    #set prefix=""
    #else
    #set prefix=$item.root_store + "/"
    #end if
    #if $item_group.label == "daily"
    #set rel_ver_label = $release.name + "-daily"
    #else if $item_group.label == "release"
    #set rel_ver_label = $release.name + "-" + $release.version
    #else if $item_group.label.startswith("beta")
    #set rel_ver_label = $release.name + "-" + $release.version + "-" + $item_group.label
    #else
    #set rel_ver_label = $release.name + "-" + $item_group.label
    #end if
    #set name="ubuntu-" + $rel_ver_label + "-" + $arch.name + "-" + $build.name + "-" + $item_group.serial
    - name: $prefix$name
      root_store: ${item.root_store}
      virt_type: ${item.vtype}
      image_id: ${item.id}
   #end for
#end for

tags:
  region: ${region.name}
  arch: ${arch.name}
  release: ${release.name}
  version: "${release.version}"
  stream: ${stream.name}
  cloud: ${cloud.name}
  region: ${region.name}
  build: ${build.name}
  endpoint: https://ec2.${region.name}.amazonaws.com
"""

COLLECTION_TEMPLATE = """
description: Ubuntu Certified Public Cloud image id streams
format: stream-collection:1.0

streams:
#for $stream in $streams:
 - path: $stream.path
 #for $tag in $stream.tags:
   $tag: "$stream.tags[$tag]"
 #end for
#end for

tags:
 #for tag in $tags:
 $tag: ${tags[tag]}
 #end for
"""

def load_query(path, cloud="aws", tree=None):
    streams = [f[0:-len(".latest.txt")]
               for f in os.listdir(path)
                   if f.endswith("latest.txt")]
    if tree is None:
        tree = {}

    # $stream/$cloud/$region/$buildname/$release/$arch
    # $stream/aws/$region/${buildname}/${release['name']}/${arch}"]
    for stream in streams:
        if stream not in tree:
            tree[stream] = {cloud: {}}
        id_files = []

        latest_f = "%s/%s.latest.txt" % (path, stream)

        # get the builds and releases
        with open(latest_f) as fp:
            for line in fp.readlines():
                (rel, build, _stream, _serial) = line.split("\t")

                if ((len(BUILDS) and build not in BUILDS) or
                    (len(RELEASES) and rel not in RELEASES)):
                    continue

                id_files.append("%s/%s/%s/%s.txt" %
                    (path, rel, build, stream))

        cdata = tree[stream][cloud]
        for id_file in id_files:
            lines = reversed(open(id_file).readlines())
            for line in lines:
                line = line.rstrip("\n\r") + "\tBOGUS"
                (rel, build, label, serial, store, arch, region,
                 iid, _kern, _rmd, vtype, _bogus) = line.split("\t", 11)

                if region not in cdata:
                    cdata[region] = {}
                if build not in cdata[region]:
                    cdata[region][build] = {}
                if rel not in cdata[region][build]:
                    cdata[region][build][rel] = {}
                if arch not in cdata[region][build][rel]:
                    cdata[region][build][rel][arch] = []

                item_groups = cdata[region][build][rel][arch]

                item_group = None
                for ig in item_groups:
                    if ig['serial'] == serial:
                        item_group = ig

                if not item_group:
                    # check NUM_DAILIES
                    if (stream == "daily" and
                        len(item_groups) == NUM_DAILIES):
                        break
                    item_group = {'serial': serial, 'items': []}
                    item_groups.append(item_group)

                # item groups (same serial) all have the same label
                item_group['label'] = label
                cur_item = {'root_store': store,
                            'vtype': vtype, 'id': iid}
                item_group['items'].append(cur_item)

    return tree


def name2ver(indict):
    indict.update(toolutil.REL2VER[indict['name']])


def streamwriter(item, data, path, passthrough):
    iqn = ("iqn.2005-04.com.ubuntu:public-clouds:%s:%s:%s:%s:%s:%s:stream" %
           (data['stream']['name'], data['release']['name'],
            data['build']['name'], data['arch']['name'], data['cloud']['name'],
            data['region']['name']))
    data['iqn'] = iqn

    params = data.copy()
    params['item_groups'] = item
    rpath = "streams/v1/%s%s" % (path, CONTENT_EXT)
    fname = os.path.join(passthrough['output_d'], rpath)

    toolutil.mkdir_p(os.path.dirname(fname))

    # this is horrible, in that we render a yaml through the cheetah template
    # and then load it and write json.
    yaml_rendered = toolutil.render_string(passthrough['template'], params)
    data = yaml.load(yaml_rendered)

    with open(fname, "w") as fp:
        fp.write(json.dumps(data, indent=1))

    passthrough['streams'].append(rpath)
    sys.stderr.write(fname + "\n")


def main():
    parser = argparse.ArgumentParser(description="create example content tree")

    parser.add_argument("query_tree", metavar='query_tree',
                        help=('read in content from /query tree. Hint: ' +
                              GET_QUERY))

    parser.add_argument("out_d", metavar='out_d',
                        help=('create content under output_dir'))

    parser.add_argument('--sign', action='store_true', default=False,
                        help='sign all generated files')

    args = parser.parse_args()

    tree = load_query(args.query_tree, cloud="aws")

    layout = [
        {"name": "stream"},
        {"name": "cloud"},
        {"name": "region"},
        {"name": "build"},
        {"name": "release", "populate": name2ver},
        {"name": "arch"},
    ]

    args.out_d = os.path.abspath(args.out_d)
    passthrough = {'output_d': args.out_d,
        'template': STREAM_TEMPLATE.lstrip(),
        'streams': [],
        'collections': [],
        'sign': args.sign,
        }

    toolutil.process(tree, {}, 0, layout, streamwriter, passthrough)

    tmpl = COLLECTION_TEMPLATE.lstrip()

    def collwriter(path, path_prefix, collection):
        if path != "/":
            # only writing to top level collection for now.
            return

        coll_file_rel = "streams/v1%sstreams%s" % (path, CONTENT_EXT)
        coll_file = os.path.join(path_prefix, coll_file_rel)

        data = yaml.safe_load(toolutil.render_string(tmpl, collection))
        toolutil.mkdir_p(os.path.dirname(coll_file))
        with open(coll_file, "w") as cfp:
            cfp.write(json.dumps(data, indent=1))

        passthrough['collections'].append(coll_file_rel)


    toolutil.process_collections(passthrough['streams'], args.out_d,
                                 collwriter)

    if args.sign:
        for path in passthrough['streams'] + passthrough['collections']:
            toolutil.signjs_file(os.path.join(args.out_d, path))

    with open(os.path.join(args.out_d, "MIRROR.info"), "w") as mfp:
        mfp.write(toolutil.dumps({
            'iqn': 'iqn.2005-04.com.ubuntu:public-clouds',
            'authoritative_mirror': 'http://cloud-images.ubuntu.com/eightprotons/cloud',
            'mirrors': []
            }))
    return

if __name__ == '__main__':
    sys.exit(main())

# vi: ts=4 expandtab
